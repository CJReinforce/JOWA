defaults:
  - _self_
  - tokenizer: default
  - world_model: default
  - actor_critic: default

wandb:
  mode: online
  project: ScalingWorldModel
  entity: null
  name: null
  group: tokenizer_plus_world_model_plus_critic  # _plus_critic
  tags: null
  notes: null

initialization:
  load_tokenizer: outputs/world_model_plus_critic/2024-05-16/15-45-36/checkpoints/epoch_120_step_5500
  load_world_model: ${initialization.load_tokenizer}

common:
  epochs: 200
  device: cuda
  do_checkpoint: True
  seed: 0
  sequence_length: ${world_model.max_blocks}

training:
  should: True
  world_size: 8
  log_interval: 10
  max_ckpts: 20
  dtype: bfloat16
  tokenizer:
    should: False  # False
    learning_rate: 0.00001
    batch_num_samples: 256
    max_grad_norm: 1.0
  world_model:
    learning_rate: 0.00001  # 0.00001
    critic_lr: 0.00025
    alpha_lr: 0.0  # 0.0003
    train_critic: True  # True
    batch_num_samples: 192  # 144
    max_grad_norm: 1.0
    weight_decay: 0.01
    imagine_horizon: ${common.sequence_length}

evaluation:
  should: False
  every: 1
  tokenizer:
    should: ${training.tokenizer.should}
    batch_num_samples: ${training.tokenizer.batch_num_samples}
  world_model:
    epochs: 0
    batch_num_samples: ${training.world_model.batch_num_samples}
    train_critic: ${training.world_model.train_critic}
    imagine_horizon: ${common.sequence_length}
    save_reconstructions: True

datasets:
  train:
    num_of_workers: 4
  test:
    num_of_workers: ${datasets.train.num_of_workers}

hydra:
  run:
    dir: .
  output_subdir: null