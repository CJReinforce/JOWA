defaults:
  - _self_
  - tokenizer: default
  - world_model: default

wandb:
  mode: online
  project: ScalingWorldModel
  entity: null
  name: null
  group: world_model
  tags: null
  notes: null

initialization:
  load_tokenizer: /home/sitonholy/programs/ScalingWorldModel/outputs/2024-03-10/02-17-49/checkpoints/epoch_82_step_400406
  load_world_model: /home/sitonholy/programs/ScalingWorldModel/outputs/world_model/2024-04-04/11-44-17/checkpoints/epoch_47_step_35203
  # load_world_model: /home/sitonholy/programs/ScalingWorldModel/outputs/world_model/2024-04-04/21-12-49/checkpoints/epoch_100_step_39697
  load_actor_critic: null

common:
  epochs: 1
  device: cuda
  do_checkpoint: True
  seed: 0
  sequence_length: ${world_model.max_blocks}

training:
  should: False
  learning_rate: 0.0001
  world_size: 8
  log_interval: 100
  max_ckpts: 10
  dtype: bfloat16
  tokenizer:
    batch_num_samples: 256
    grad_acc_steps: 1
    max_grad_norm: 10.0
  world_model:
    batch_num_samples: 64
    grad_acc_steps: 1
    max_grad_norm: 10.0
    weight_decay: 0.01

evaluation:
  should: True
  every: 1
  tokenizer:
    batch_num_samples: ${training.tokenizer.batch_num_samples}
    save_reconstructions: True
  world_model:
    epochs: 10
    batch_num_samples: ${training.world_model.batch_num_samples}
    save_reconstructions: True
  actor_critic:
    num_episodes_to_save: ${training.actor_critic.batch_num_samples}
    horizon: ${training.actor_critic.imagine_horizon}

datasets:
  train:
    num_of_workers: 4
  test:
    num_of_workers: ${datasets.train.num_of_workers}

hydra:
  run:
    dir: .
  output_subdir: null